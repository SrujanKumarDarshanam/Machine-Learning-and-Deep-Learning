{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e58bf3",
   "metadata": {},
   "source": [
    "# <font color='red'> Model-2 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415855d",
   "metadata": {},
   "source": [
    "Use the same model as above but for 'input_seq_total_text_data' give only some words in the sentance not all the words. Filter the words as below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd5a2c",
   "metadata": {},
   "source": [
    "<pre>\n",
    "1. Fit TF-IDF vectorizer on the Train data <br>\n",
    "2. Get the idf value for each word we have in the train data. Please go through <a  href='https://stackoverflow.com/questions/23792781/tf-idf-feature-weights-using-sklearn-feature-extraction-text-tfidfvectorizer'>this</a><br>\n",
    "\n",
    "3. Do some analysis on the Idf values and based on those values choose the low and high threshold value. Because very \n",
    "frequent words and very very rare words don't give much information.\n",
    "Hint - A preferable IDF range is 2-11 for model 2. <br>\n",
    "4.Remove the low idf value and high idf value words from the train and test data. You can go through each of the\n",
    "sentence of train and test data and include only those features(words) which are present in the defined IDF range.\n",
    "5. Perform tokenization on the modified text data same as you have done for previous model.\n",
    "6. Create embedding matrix for model 2 and then use the rest of the features similar to previous model.\n",
    "7. Define the model, compile and fit the model.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6802c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea7b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense, Input , Dropout\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9718d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file\n",
    "\n",
    "p1 = '/content/drive/MyDrive/AAIC/Assignments/LSTM on Donors Choose/preprocessed_data_final.csv'\n",
    "p2 = \"C:/Users/darsh/Downloads/Srujan/Donars Choose Assignment/preprocessed_data_final.csv\"\n",
    "df_2 = pd.read_csv(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb21ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = ['essay','project_title','project_resource_summary',]\n",
    "df_2['total_text_input'] = df_2['essay'] + ' ' + df_2['project_title'] + ' ' + df_2['project_resource_summary']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584fc711",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus = df_2['total_text_input']\n",
    "vectorizer = TfidfVectorizer(min_df=15)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "idf = vectorizer.idf_\n",
    "idf_values = (dict(zip(vectorizer.get_feature_names_out(), idf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d35eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = pd.DataFrame(idf_values.items(),columns=['word_features','idf_values']).sort_values(['idf_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e64745d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='idf_values'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAGxCAYAAAAH0U5DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZD0lEQVR4nO3de5CWdf3/8de9LO2uuIAgoJugkE6oYImaJZnMaCqTNB7yEKviZNoUpmBqZOMpzzrlsTxlOv6EtBnD04SlZqgdPCWMpINmNjh5wEPJQSFg798fxn5ZP+BhAe/VfTxmdmbv6977c793r2XvJ9d137uVarVaDQDAKupqPQAA0PUIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAr1nb1hW1tbXnjhhTQ3N6dSqazLmQCA9aRarWbhwoVpaWlJXd2ajxN0OhBeeOGFDB48uLM3BwBq6Pnnn89mm222xus7HQjNzc3td9C7d+/OLgMAfIgWLFiQwYMHtz+Or0mnA2HlaYXevXsLBAD4iHmvpwd4kiIAUBAIAEBBIAAABYEAABQEAgBQEAgAQEEgAAAFgQAAFAQCAFAQCABAQSAAAAWBAAAUBAIAUBAIAEBBIAAABYEAABQEAgBQEAgAQEEgAAAFgQAAFAQCAFAQCABAQSAAAAWBAAAUBAIAUBAIAEBBIAAABYEAABQEAgBQEAgAQEEgAAAFgQAAFOprPQDAR1W1Ws2SJUtqPUaXUq1Ws3Tp0iRJQ0NDKpVKjSfqvMbGxo/0/GtLIAB00pIlSzJ27Nhaj8F6MmPGjDQ1NdV6jJpxigEAKDiCALAOLPrs11Ot8yM1K5alefZNSZKFnzkk6dGzxgN9MJW25dlw1i9rPUaX4LsZYB2o1tV/5B4M17sePT9yX5NqrQfoQpxiAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACvW1HgCq1WqWLFmSJGlsbEylUqnxRAC101V+JjqCQM0tWbIkY8eOzdixY9v/UQB0V13lZ6JAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACvW1HuCdTj/99PzhD3/ImDFjsueee+aSSy7Jcccdl1122SVJ8qc//ek9t628vPXWW+f+++9Pa2trjjzyyA5rn3766R3ud3Xrrrp91bW23nrrXHLJJRkwYEDmzJmThoaGHHTQQbnjjjuSJOPGjcsdd9yRt956K0uXLk2S1NXVpa2tLb169cpOO+2U+++/P9tss03+9re/ZYMNNsj+++/f4TaVSiXVarV9jvr6+ixfvrzYniQ9evRIW1tbsb2zhgwZknnz5q2TtQD4aKpUO/mosmDBgvTp0ydvvPFGevfuvU6Gefnll3PwwQe3X+7Xr19ef/31bLzxxrnxxhuTJIceemheffXVNW77+c9/nm9+85t59dVX29epq6vLVVddlaOOOqp9280335xBgwYlSZYsWVKs29jY2GH7SpVKJRtttFFef/31dfI509Fll12WkSNH1noMeF/eeuutjB07NkmycNRhSY+eNZ6oC1ixLM1//X9JPqJfk1XmnzFjRpqamj70EVb9vlofM7zfx+8udYrhmGOO6XB55YPwa6+9lmnTpmXq1Kl57bXX3nXbKaec0n55pba2tnz729/usO273/1u+/urW/ed21eqVqviYD2aPHlyrUcAIF3oFMNdd92VV155ZbXXVavVTJ06tf39d9v2xBNPrHaN5cuXd7g8f/783HXXXRkxYkSmTZvWYY1p06Zlu+2267CdD8fy5ctz+eWX58gjj6z1KPCelixZ8n8X/Kz4eFhlP3bYvx+iVe+3lo9B7/sUw9KlS9vPpydvH6IYPHjwOjnFsGLFiuy5555ZsWLFWq3zQdXV1WXUqFF5/PHHO9x3XV1dNtxwwyxcuFAgAO/Lws8cknxig1qPUXsf9VMM/30zzbNvqvUU7aZPn56NNtpona65zk8xnHvuuenTp0/72+DBg9fJoEly5513fuhxkLx96uHRRx8t7rutrS0LFiwQBwB0W+/7FMMPfvCDHH/88e2XVx5BWBf22WefXHrppR96JPTo0SPbb7+9Iwhd0O23356ePT9i//Og21myZEn222+/ty/UdZkztqyNVfbj9OnT09jY+KGPsOr3VUNDw4d+/yu97+/ohoaG9TZojx49cuKJJ+a88857149J0uGBfHXbPojvf//72WabbTJhwoQO2+vq6nLaaaflpJNOqsmRje5u/Pjx6+yVMfChqVRqPQHrwir7sbGxsSavYlhVpYbfV13mVQx77713BgwYsNrrKpVKWltbM378+PYv1pq2jRw5crVf0Pr6ji00cODA7Lnnntlss82KNcaPH58ddtihw3Y+HPX19Tn66KNrPQZAt9dlAiFJLr/88g6X+/XrlyTZeOONM378+LS2tqZ///7vuu3MM89sv7xSXV1drrjiig7bLrvssvb3V7fuO7evVKlU2udaE1HReRdddFGtRwAgXSwQBg0alDFjxiRJxowZkxNOOCGDBg3K5MmT09jYmMbGxhx//PHvuq1v377tl8eMGZO6urq0trZmq6226rD2yl+SlGS1675z+8q1Dj300Pa5RowYkeTt0y+HHXZY+vbtm759++bQQw9N3759O5ySqat7+0vdq1ev9rVGjBiRSqWSXr16td9+5W3eGRkrj4CsLj569OixTqNkyJAh62ytD2rLLbes2X0D8H+61G9SpHta3781DNYXv0lxNT7qL3P0mxTbdakjCABA1yAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKNTXegBobGzMjBkz2t8H6M66ys9EgUDNVSqVNDU11XoMgC6hq/xMdIoBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBACgIBACgIBAAgIJAAAAKAgEAKAgEAKAgEACAgkAAAAoCAQAo1Nd6AICPg0rb8lRrPURXsGLZ6t//iKi0La/1CF2GQABYBzac9ctaj9DlNM++qdYjsBacYgAACo4gAHRSY2NjZsyYUesxupRqtZqlS5cmSRoaGlKpVGo8Uec1NjbWeoSaEggAnVSpVNLU1FTrMbqcDTbYoNYjsA44xQAAFAQCAFAQCABAQSAAAAWBAAAUBAIAUBAIAEBBIAAABYEAABQEAgBQEAgAQEEgAAAFgQAAFAQCAFAQCABAQSAAAAWBAAAUBAIAUBAIAEBBIAAABYEAABQEAgBQEAgAQEEgAAAFgQAAFAQCAFAQCABAQSAAAAWBAAAUBAIAUBAIAEBBIAAABYEAABTqO3vDarWaJFmwYME6GwYAWL9WPm6vfBxfk04HwsKFC5MkgwcP7uwSAECNLFy4MH369Fnj9ZXqeyXEGrS1teWFF15Ic3NzKpVKpwf8OFuwYEEGDx6c559/Pr179671OKzCvuma7JeuyX7pmjq7X6rVahYuXJiWlpbU1a35mQadPoJQV1eXzTbbrLM371Z69+7tH1UXZd90TfZL12S/dE2d2S/vduRgJU9SBAAKAgEAKAiE9aihoSGnnXZaGhoaaj0K72DfdE32S9dkv3RN63u/dPpJigDAx5cjCABAQSAAAAWBAAAUBMJ6cO6552annXZKc3NzBg4cmH333Tdz586t9Vi8w3nnnZdKpZJJkybVepRu71//+lcOPfTQ9O/fP01NTRk5cmQeffTRWo/Vra1YsSKnnHJKhg4dmqampnzqU5/KmWee+Z6/npd17/7778+4cePS0tKSSqWSW2+9tcP11Wo1p556ajbddNM0NTVljz32yDPPPLPW9ysQ1oOZM2dm4sSJ+ctf/pK77747y5Yty5577pnFixfXejT+55FHHslVV12V7bbbrtajdHv//ve/M3r06PTs2TMzZszIk08+mR//+MfZaKONaj1at3b++efniiuuyOWXX56nnnoq559/fi644IJcdtlltR6t21m8eHE+85nP5Kc//elqr7/gggty6aWX5sorr8xDDz2UXr16Za+99sqSJUvW6n69iuFD8Morr2TgwIGZOXNmvvSlL9V6nG5v0aJFGTVqVH72s5/lrLPOymc/+9lcfPHFtR6r25oyZUr++Mc/5oEHHqj1KKxin332yaBBg3Lttde2bzvggAPS1NSUG2+8sYaTdW+VSiXTp0/Pvvvum+TtowctLS353ve+lxNOOCFJ8sYbb2TQoEG5/vrrc8ghh3T6vhxB+BC88cYbSZJ+/frVeBKSZOLEifnKV76SPfbYo9ajkOT222/PjjvumAMPPDADBw7M9ttvn2uuuabWY3V7u+yyS+699948/fTTSZLZs2fnwQcfzNixY2s8Gat67rnn8tJLL3X4edanT5/svPPO+fOf/7xWa3f6bzHw/rS1tWXSpEkZPXp0RowYUetxur2bbropf/3rX/PII4/UehT+5x//+EeuuOKKHH/88Tn55JPzyCOP5Nhjj80nPvGJTJgwodbjdVtTpkzJggULMnz48PTo0SMrVqzI2WefndbW1lqPxipeeumlJMmgQYM6bB80aFD7dZ0lENaziRMnZs6cOXnwwQdrPUq39/zzz+e4447L3XffncbGxlqPw/+0tbVlxx13zDnnnJMk2X777TNnzpxceeWVAqGGfvWrX2Xq1KmZNm1att1228yaNSuTJk1KS0uL/dJNOMWwHh1zzDG58847c9999/nLl13AY489lvnz52fUqFGpr69PfX19Zs6cmUsvvTT19fVZsWJFrUfsljbddNNss802HbZtvfXWmTdvXo0mIklOPPHETJkyJYccckhGjhyZww47LJMnT865555b69FYxSabbJIkefnllztsf/nll9uv6yyBsB5Uq9Ucc8wxmT59en7/+99n6NChtR6JJLvvvnueeOKJzJo1q/1txx13TGtra2bNmpUePXrUesRuafTo0cXLgJ9++ulsvvnmNZqIJHnzzTdTV9fxIaJHjx5pa2ur0USsztChQ7PJJpvk3nvvbd+2YMGCPPTQQ/nCF76wVms7xbAeTJw4MdOmTcttt92W5ubm9vNAffr0SVNTU42n676am5uL54H06tUr/fv39/yQGpo8eXJ22WWXnHPOOTnooIPy8MMP5+qrr87VV19d69G6tXHjxuXss8/OkCFDsu222+bxxx/PT37yk3zjG9+o9WjdzqJFi/L3v/+9/fJzzz2XWbNmpV+/fhkyZEgmTZqUs846K1tttVWGDh2aU045JS0tLe2vdOi0KutcktW+XXfddbUejXfYbbfdqscdd1ytx+j27rjjjuqIESOqDQ0N1eHDh1evvvrqWo/U7S1YsKB63HHHVYcMGVJtbGysDhs2rPrDH/6wunTp0lqP1u3cd999q31MmTBhQrVarVbb2tqqp5xySnXQoEHVhoaG6u67716dO3fuWt+v34MAABQ8BwEAKAgEAKAgEACAgkAAAAoCAQAoCAQAoCAQAICCQAAACgIBupgxY8Zk0qRJa7x+iy22yMUXX9x++aWXXsqXv/zl9OrVK3379l3v8/3zn/9MpVLJrFmz1vt9AbXjbzFAF/PrX/86PXv2fN8ff9FFF+XFF1/MrFmz0qdPn/U4GdCdCAToYvr16/eBPv7ZZ5/NDjvskK222mo9TQR0R04xQBez6imG+fPnZ9y4cWlqasrQoUMzderUDh+7xRZb5JZbbskNN9yQSqWSI4444l3XHj9+fA4++OAO25YtW5aNN944N9xwQ5Lkrrvuyhe/+MX07ds3/fv3zz777JNnn312jWtef/31xamNW2+9NZVKpcO22267LaNGjUpjY2OGDRuWM844I8uXL0/y9p9IP/300zNkyJA0NDSkpaUlxx577Lt+LsD65QgCdGFHHHFEXnjhhdx3333p2bNnjj322MyfP7/9+kceeSSHH354evfunUsuueQ9/5x4a2trDjzwwCxatCgbbrhhkuS3v/1t3nzzzey3335JksWLF+f444/Pdtttl0WLFuXUU0/Nfvvtl1mzZqWurnP/p3jggQdy+OGH59JLL82uu+6aZ599NkcffXSS5LTTTsstt9ySiy66KDfddFO23XbbvPTSS5k9e3an7gtYNwQCdFFPP/10ZsyYkYcffjg77bRTkuTaa6/N1ltv3f4xAwYMSENDQ5qamrLJJpu855p77bVXevXqlenTp+ewww5LkkybNi1f/epX09zcnCQ54IADOtzmF7/4RQYMGJAnn3wyI0aM6NTncsYZZ2TKlCmZMGFCkmTYsGE588wzc9JJJ+W0007LvHnzsskmm2SPPfZIz549M2TIkHzuc5/r1H0B64ZTDNBFPfXUU6mvr88OO+zQvm348OFr9UqF+vr6HHTQQe2nKhYvXpzbbrstra2t7R/zzDPP5Otf/3qGDRuW3r17Z4sttkiSzJs3r9P3O3v27PzoRz/Khhtu2P521FFH5cUXX8ybb76ZAw88MG+99VaGDRuWo446KtOnT28//QDUhiMI0M20trZmt912y/z583P33Xenqakpe++9d/v148aNy+abb55rrrkmLS0taWtry4gRI/Lf//53tevV1dWlWq122LZs2bIOlxctWpQzzjgj+++/f3H7xsbGDB48OHPnzs0999yTu+++O9/5zndy4YUXZubMmR/oFR3AuiMQoIsaPnx4li9fnscee6z9FMPcuXPzn//8Z63W3WWXXTJ48ODcfPPNmTFjRg488MD2B+HXXnstc+fOzTXXXJNdd901SfLggw++63oDBgzIwoULs3jx4vTq1StJit+RMGrUqMydOzdbbrnlGtdpamrKuHHjMm7cuEycODHDhw/PE088kVGjRq3FZwt0lkCALurTn/509t5773zrW9/KFVdckfr6+kyaNOk9n4j4fowfPz5XXnllnn766dx3333t2zfaaKP0798/V199dTbddNPMmzcvU6ZMede1dt5552ywwQY5+eSTc+yxx+ahhx7K9ddf3+FjTj311Oyzzz4ZMmRIvva1r6Wuri6zZ8/OnDlzctZZZ+X666/PihUr2te68cYb09TUlM0333ytP1egczwHAbqw6667Li0tLdltt92y//775+ijj87AgQPXet3W1tY8+eST+eQnP5nRo0e3b6+rq8tNN92Uxx57LCNGjMjkyZNz4YUXvuta/fr1y4033pjf/OY3GTlyZH75y1/m9NNP7/Axe+21V+6888787ne/y0477ZTPf/7zueiii9oDoG/fvrnmmmsyevTobLfddrnnnntyxx13pH///mv9uQKdU6m+8+QhANDtOYIAABQEAnyMTJ06tcNLCVd923bbbWs9HvAR4hQDfIwsXLgwL7/88mqv69mzpyf9Ae+bQAAACk4xAAAFgQAAFAQCAFAQCABAQSAAAAWBAAAUBAIAUBAIAEDh/wPFPNzNBuvjugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=word_features['idf_values'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "351d2f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(word_features['idf_values'],orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2465cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 6.88025485, 9.16739776, 9.60565269])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentiles = np.percentile(word_features['idf_values'],np.arange(0,100))[[0,25,75,90]]\n",
    "percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0726bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = word_features[(word_features.idf_values >= percentiles[1]) & (word_features.idf_values <= percentiles[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395cbc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(word_features['word_features'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d942f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_words = set(vectorizer.get_feature_names()).difference(set(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64d8ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 109248/109248 [00:22<00:00, 4912.87it/s]\n"
     ]
    }
   ],
   "source": [
    "final_text = dict()\n",
    "df_2['text_data_for_model_2'] = \"\"\n",
    "for indx in tqdm(df_2['total_text_input'].index):\n",
    "    temp_list = list()\n",
    "    for j in df_2['total_text_input'][indx].split():\n",
    "        if j not in dummy_words:\n",
    "            temp_list.append(j)\n",
    "    final_text[indx] = \" \".join(temp_list)\n",
    "    df_2['text_data_for_model_2'].loc[indx] = \" \".join(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce27e9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>resource_summary_contains_numerical_digits</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>essay</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>total_text_input</th>\n",
       "      <th>text_data_for_model_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [teacher_number_of_previously_posted_projects, resource_summary_contains_numerical_digits, price, quantity, school_state, project_grade_category, clean_categories, clean_subcategories, teacher_prefix, project_is_approved, essay, project_title, project_resource_summary, total_text_input, text_data_for_model_2]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_2[pd.isnull(df_2).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d1710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "866a0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_2['project_is_approved'].values\n",
    "df_2.drop(['project_is_approved'],axis=1,inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_2, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.10,\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe3cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09319984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ddc8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 1000\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "# Tokenize our training data\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(X_train['text_data_for_model_2'])\n",
    "\n",
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Encode training data sentences into sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train['text_data_for_model_2'])\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test['text_data_for_model_2'])\n",
    "\n",
    "# Get max training sequence length\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "\n",
    "# Pad the training sequences\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "test_padded = pad_sequences(test_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72f3b087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a4f3195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padded training shape, Test Shape: (98323, 122) (10925, 122)\n",
      "Training sequences data type: <class 'list'> <class 'list'>\n",
      "Padded Training sequences data type: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Output the results of our work\n",
    "#print(\"Word index:\\n\", word_index)\n",
    "#print(\"\\nTraining sequences:\\n\", train_sequences)\n",
    "#print(\"\\nPadded training sequences:\\n\", train_padded)\n",
    "print(\"\\nPadded training shape, Test Shape:\", train_padded.shape,test_padded.shape)\n",
    "print(\"Training sequences data type:\", type(train_sequences),type(test_sequences))\n",
    "print(\"Padded Training sequences data type:\", type(train_padded),type(test_padded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "612e3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:21, 18381.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "p1 = '/content/drive/MyDrive/AAIC/Assignments/LSTM on Donors Choose/glove.6B.300d.txt'\n",
    "p2 = \"C:/Users/darsh/Downloads/Srujan/Donars Choose Assignment/glove.6B.300d.txt\"\n",
    "f = open(p2,encoding=\"utf8\")\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('\\nLoaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14ee5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0b06ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbded55",
   "metadata": {},
   "source": [
    "# <font color='blue'> Categorical feature Vectorization </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d111720",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0993aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_state_enc = (enc.fit_transform(np.array(X_train['school_state']).reshape(-1,1)))\n",
    "teacher_prefix_enc = (enc.fit_transform(np.array(X_train['teacher_prefix']).reshape(-1,1)))\n",
    "project_grade_category_enc = (enc.fit_transform(np.array(X_train['project_grade_category']).reshape(-1,1)))\n",
    "clean_categories_enc = (enc.fit_transform(np.array(X_train['clean_categories']).reshape(-1,1)))\n",
    "clean_subcategories_enc = (enc.fit_transform(np.array(X_train['clean_subcategories']).reshape(-1,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9eed84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_state_enc_test = (enc.transform(np.array(X_test['school_state']).reshape(-1,1)))\n",
    "teacher_prefix_enc_test = (enc.transform(np.array(X_test['teacher_prefix']).reshape(-1,1)))\n",
    "project_grade_category_enc_test = (enc.transform(np.array(X_test['project_grade_category']).reshape(-1,1)))\n",
    "clean_categories_enc_test = (enc.transform(np.array(X_test['clean_categories']).reshape(-1,1)))\n",
    "clean_subcategories_enc_test = (enc.transform(np.array(X_test['clean_subcategories']).reshape(-1,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09559be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f5bd14b",
   "metadata": {},
   "source": [
    " # <font color='blue'>Numerical Feature Vectorization </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29a441c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_input = ['teacher_number_of_previously_posted_projects',\n",
    "                   'resource_summary_contains_numerical_digits',\n",
    "                   'price','quantity'\n",
    "                  ]\n",
    "\n",
    "scaler  = preprocessing.StandardScaler().fit(X_train[numerical_input])\n",
    "std_data_train = np.array(pd.DataFrame(scaler.transform(X_train[numerical_input]),columns=numerical_input))\n",
    "std_data_test = np.array(pd.DataFrame(scaler.transform(X_test[numerical_input]),columns=numerical_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f592a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68be8a50",
   "metadata": {},
   "source": [
    "# <font color='blue'>defining the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cfa7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_in_school_state = (len(set(pd.DataFrame(school_state_enc)[0])))\n",
    "elements_in_teacher_prefix = (len(set(pd.DataFrame(teacher_prefix_enc)[0])))\n",
    "elements_in_project_grade_category = (len(set(pd.DataFrame(project_grade_category_enc)[0])))\n",
    "elements_in_clean_categories = (len(set(pd.DataFrame(clean_categories_enc)[0])))\n",
    "elements_in_clean_subcategories = (len(set(pd.DataFrame(clean_subcategories_enc)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8448b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fb2a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_total_text_data = Input(shape=(maxlen,),name='input_seq_total_text_data_')\n",
    "emb_text_data = Embedding(input_dim=vocab_size,output_dim=300, \n",
    "                          weights=[embedding_matrix], input_length=maxlen,trainable=False,\n",
    "                          name='emb_text_data')(input_seq_total_text_data)\n",
    "lstm = LSTM(units=25,activation='tanh',return_sequences=True)(emb_text_data)\n",
    "flatten_text = Flatten()(lstm)\n",
    "\n",
    "input_school_state = Input(shape=1,name='input_school_state')\n",
    "input_school_state_emb = Embedding(input_dim=elements_in_school_state,\n",
    "                                   output_dim=int(min(elements_in_school_state / 2, 50)),\n",
    "                                   input_length=1,\n",
    "                                  name='input_school_state_emb')(input_school_state)\n",
    "flatten_school_state = Flatten()(input_school_state_emb)\n",
    "\n",
    "\n",
    "input_grade_category = Input(shape=1,name='input_grade_category')\n",
    "input_grade_category_emb = Embedding(input_dim=elements_in_project_grade_category,\n",
    "                                   output_dim=int(min(elements_in_project_grade_category / 2, 50)),\n",
    "                                   input_length=1,\n",
    "                                  name='input_grade_category_emb')(input_grade_category)\n",
    "flatten_grade_category = Flatten()(input_grade_category_emb)\n",
    "\n",
    "\n",
    "input_clean_categories = Input(shape=1,name='input_clean_categories')\n",
    "input_clean_categories_emb = Embedding(input_dim=elements_in_clean_categories,\n",
    "                                      output_dim=int(min(elements_in_clean_categories / 2, 50)),\n",
    "                                      input_length=1,\n",
    "                                      name='input_clean_categories_emb')(input_clean_categories)\n",
    "flatten_clean_categories = Flatten()(input_clean_categories_emb)\n",
    "\n",
    "\n",
    "\n",
    "input_clean_sub_categories = Input(shape=1,name='input_clean_sub_categories')\n",
    "input_clean_sub_categories_emb = Embedding(input_dim=elements_in_clean_subcategories,\n",
    "                                      output_dim=int(min(elements_in_clean_subcategories / 2, 50)),\n",
    "                                      input_length=1,\n",
    "                                      name='input_clean_sub_categories_emb')(input_clean_sub_categories)\n",
    "flatten_clean_sub_categories = Flatten()(input_clean_sub_categories_emb)\n",
    "\n",
    "\n",
    "input_teacher_prefix = Input(shape=1,name='input_teacher_prefix')\n",
    "input_teacher_prefix_emb = Embedding(input_dim=elements_in_teacher_prefix,\n",
    "                                      output_dim=int(min(elements_in_teacher_prefix / 2, 50)),\n",
    "                                      input_length=1,\n",
    "                                      name='input_teacher_prefix_emb')(input_teacher_prefix)\n",
    "flatten_teacher_prefix = Flatten()(input_teacher_prefix_emb)\n",
    "\n",
    "\n",
    "\n",
    "input_remaining = Input(shape=4,name='input_remaining')\n",
    "input_remaining_dense = Dense(units=128,activation='relu',\n",
    "                               kernel_initializer='he_normal',kernel_regularizer=l2(0.00001),\n",
    "                              name='input_remaining_dense')(input_remaining)\n",
    "flatten_remaining = Flatten()(input_remaining_dense)\n",
    "\n",
    "concat_layer = concatenate([flatten_text,flatten_school_state,flatten_grade_category,\n",
    "                            flatten_clean_categories,flatten_clean_sub_categories,\n",
    "                            flatten_teacher_prefix,flatten_remaining],)\n",
    "\n",
    "dense_layer1_after_concat = Dense(units=128,activation='relu',\n",
    "                                  kernel_initializer='he_normal',kernel_regularizer=l2(0.00001),\n",
    "                                  name='dense_layer1_after_concat')(concat_layer)\n",
    "drop1 = Dropout(0.5)(dense_layer1_after_concat)\n",
    "\n",
    "dense_layer2_after_concat = Dense(units=128,activation='relu',\n",
    "                                  kernel_initializer='he_normal',kernel_regularizer=l2(0.00001),\n",
    "                                  name='dense_layer2_after_concat')(drop1)\n",
    "drop2 = Dropout(0.5)(dense_layer2_after_concat)\n",
    "\n",
    "bn1 = BatchNormalization()(drop2)\n",
    "\n",
    "dense_layer3_after_concat = Dense(units=128,activation='relu',\n",
    "                                  kernel_initializer='he_normal',kernel_regularizer=l2(0.00001),\n",
    "                                  name='dense_layer3_after_concat')(bn1)\n",
    "drop3 = Dropout(0.5)(dense_layer3_after_concat)\n",
    "\n",
    "dense_layer4_after_concat = Dense(units=128,activation='relu',\n",
    "                                  kernel_initializer='he_normal',kernel_regularizer=l2(0.00001),\n",
    "                                  name='dense_layer4_after_concat')(drop3)\n",
    "drop4 = Dropout(0.5)(dense_layer4_after_concat)\n",
    "\n",
    "output = Dense(units=2,activation='softmax')(drop4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "772f0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Model(inputs=[input_seq_total_text_data, \n",
    "                   input_school_state,\n",
    "                   input_grade_category,\n",
    "                   input_clean_categories,\n",
    "                   input_clean_sub_categories,\n",
    "                   input_teacher_prefix,\n",
    "                   input_remaining],\n",
    "           outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7d3f5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_seq_total_text_data_ (Inp [(None, 122)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "emb_text_data (Embedding)       (None, 122, 300)     17916300    input_seq_total_text_data_[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "input_school_state (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_grade_category (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_clean_categories (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_clean_sub_categories (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_teacher_prefix (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_remaining (InputLayer)    [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 122, 25)      32600       emb_text_data[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_school_state_emb (Embeddi (None, 1, 25)        1275        input_school_state[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_grade_category_emb (Embed (None, 1, 2)         8           input_grade_category[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_clean_categories_emb (Emb (None, 1, 25)        1275        input_clean_categories[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_clean_sub_categories_emb  (None, 1, 50)        20000       input_clean_sub_categories[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "input_teacher_prefix_emb (Embed (None, 1, 2)         10          input_teacher_prefix[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_remaining_dense (Dense)   (None, 128)          640         input_remaining[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3050)         0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 25)           0           input_school_state_emb[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           input_grade_category_emb[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 25)           0           input_clean_categories_emb[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 50)           0           input_clean_sub_categories_emb[0]\n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2)            0           input_teacher_prefix_emb[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 128)          0           input_remaining_dense[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3282)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer1_after_concat (Dens (None, 128)          420224      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_layer1_after_concat[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer2_after_concat (Dens (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_layer2_after_concat[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128)          512         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer3_after_concat (Dens (None, 128)          16512       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_layer3_after_concat[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer4_after_concat (Dens (None, 128)          16512       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_layer4_after_concat[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            258         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 18,442,638\n",
      "Trainable params: 526,082\n",
      "Non-trainable params: 17,916,556\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a73aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "102b5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [test_padded,school_state_enc_test,project_grade_category_enc_test,\n",
    "            clean_categories_enc_test,clean_subcategories_enc_test,teacher_prefix_enc_test,(std_data_test)]\n",
    "\n",
    "train_data = [train_padded,school_state_enc,project_grade_category_enc,\n",
    "              clean_categories_enc,clean_subcategories_enc,teacher_prefix_enc,(std_data_train)]             \n",
    "\n",
    "y_train_enc =  tensorflow.keras.utils.to_categorical(y_train, 2)\n",
    "y_test_enc =  tensorflow.keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34d0d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc1(y_true, y_pred):\n",
    "    if len(np.unique(y_true[:,1])) == 1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return roc_auc_score( y_true, y_pred, average='macro', sample_weight=None).astype('double')\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    return tensorflow.numpy_function(auc1, (y_true, y_pred), tensorflow.double)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./LSTM_Model_2.h5', save_weights_only=False,save_best_only=True, \\\n",
    "                                       mode='max', monitor='val_auroc',verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auroc', patience=2,mode='max',verbose=1,min_lr=0.00001),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1049d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[auroc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ebb121f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "769/769 [==============================] - 22s 20ms/step - loss: 0.4851 - auroc: 0.5610 - val_loss: 0.4843 - val_auroc: 0.6053\n",
      "\n",
      "Epoch 00001: val_auroc improved from -inf to 0.60534, saving model to .\\LSTM_Model_2.h5\n",
      "Epoch 2/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.4279 - auroc: 0.6325 - val_loss: 0.4552 - val_auroc: 0.6596\n",
      "\n",
      "Epoch 00002: val_auroc improved from 0.60534 to 0.65958, saving model to .\\LSTM_Model_2.h5\n",
      "Epoch 3/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.4187 - auroc: 0.6636 - val_loss: 0.4376 - val_auroc: 0.6794\n",
      "\n",
      "Epoch 00003: val_auroc improved from 0.65958 to 0.67940, saving model to .\\LSTM_Model_2.h5\n",
      "Epoch 4/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.4131 - auroc: 0.6794 - val_loss: 0.4381 - val_auroc: 0.6842\n",
      "\n",
      "Epoch 00004: val_auroc improved from 0.67940 to 0.68418, saving model to .\\LSTM_Model_2.h5\n",
      "Epoch 5/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.4088 - auroc: 0.6905 - val_loss: 0.4281 - val_auroc: 0.6836\n",
      "\n",
      "Epoch 00005: val_auroc did not improve from 0.68418\n",
      "Epoch 6/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.4061 - auroc: 0.6964 - val_loss: 0.4190 - val_auroc: 0.6911\n",
      "\n",
      "Epoch 00006: val_auroc improved from 0.68418 to 0.69108, saving model to .\\LSTM_Model_2.h5\n",
      "Epoch 7/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.4019 - auroc: 0.7081 - val_loss: 0.4163 - val_auroc: 0.6939\n",
      "\n",
      "Epoch 00007: val_auroc improved from 0.69108 to 0.69386, saving model to .\\LSTM_Model_2.h5\n",
      "Epoch 8/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3997 - auroc: 0.7129 - val_loss: 0.4149 - val_auroc: 0.6935\n",
      "\n",
      "Epoch 00008: val_auroc did not improve from 0.69386\n",
      "Epoch 9/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3967 - auroc: 0.7223 - val_loss: 0.4196 - val_auroc: 0.6903\n",
      "\n",
      "Epoch 00009: val_auroc did not improve from 0.69386\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3882 - auroc: 0.7403 - val_loss: 0.4130 - val_auroc: 0.6881\n",
      "\n",
      "Epoch 00010: val_auroc did not improve from 0.69386\n",
      "Epoch 11/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3846 - auroc: 0.7481 - val_loss: 0.4135 - val_auroc: 0.6854\n",
      "\n",
      "Epoch 00011: val_auroc did not improve from 0.69386\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3822 - auroc: 0.7530 - val_loss: 0.4131 - val_auroc: 0.6850\n",
      "\n",
      "Epoch 00012: val_auroc did not improve from 0.69386\n",
      "Epoch 13/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3824 - auroc: 0.7516 - val_loss: 0.4129 - val_auroc: 0.6847\n",
      "\n",
      "Epoch 00013: val_auroc did not improve from 0.69386\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 14/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3821 - auroc: 0.7536 - val_loss: 0.4129 - val_auroc: 0.6843\n",
      "\n",
      "Epoch 00014: val_auroc did not improve from 0.69386\n",
      "Epoch 15/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3809 - auroc: 0.7557 - val_loss: 0.4127 - val_auroc: 0.6840\n",
      "\n",
      "Epoch 00015: val_auroc did not improve from 0.69386\n",
      "Epoch 16/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3811 - auroc: 0.7562 - val_loss: 0.4127 - val_auroc: 0.6839\n",
      "\n",
      "Epoch 00016: val_auroc did not improve from 0.69386\n",
      "Epoch 17/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3815 - auroc: 0.7546 - val_loss: 0.4126 - val_auroc: 0.6834\n",
      "\n",
      "Epoch 00017: val_auroc did not improve from 0.69386\n",
      "Epoch 18/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3806 - auroc: 0.7571 - val_loss: 0.4126 - val_auroc: 0.6834\n",
      "\n",
      "Epoch 00018: val_auroc did not improve from 0.69386\n",
      "Epoch 19/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3800 - auroc: 0.7575 - val_loss: 0.4126 - val_auroc: 0.6832\n",
      "\n",
      "Epoch 00019: val_auroc did not improve from 0.69386\n",
      "Epoch 20/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3805 - auroc: 0.7569 - val_loss: 0.4128 - val_auroc: 0.6828\n",
      "\n",
      "Epoch 00020: val_auroc did not improve from 0.69386\n",
      "Epoch 21/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3793 - auroc: 0.7584 - val_loss: 0.4127 - val_auroc: 0.6832\n",
      "\n",
      "Epoch 00021: val_auroc did not improve from 0.69386\n",
      "Epoch 22/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3791 - auroc: 0.7592 - val_loss: 0.4129 - val_auroc: 0.6828\n",
      "\n",
      "Epoch 00022: val_auroc did not improve from 0.69386\n",
      "Epoch 23/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3800 - auroc: 0.7578 - val_loss: 0.4128 - val_auroc: 0.6827\n",
      "\n",
      "Epoch 00023: val_auroc did not improve from 0.69386\n",
      "Epoch 24/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3792 - auroc: 0.7588 - val_loss: 0.4126 - val_auroc: 0.6826\n",
      "\n",
      "Epoch 00024: val_auroc did not improve from 0.69386\n",
      "Epoch 25/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3789 - auroc: 0.7589 - val_loss: 0.4125 - val_auroc: 0.6823\n",
      "\n",
      "Epoch 00025: val_auroc did not improve from 0.69386\n",
      "Epoch 26/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3782 - auroc: 0.7594 - val_loss: 0.4124 - val_auroc: 0.6825\n",
      "\n",
      "Epoch 00026: val_auroc did not improve from 0.69386\n",
      "Epoch 27/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3794 - auroc: 0.7582 - val_loss: 0.4127 - val_auroc: 0.6819\n",
      "\n",
      "Epoch 00027: val_auroc did not improve from 0.69386\n",
      "Epoch 28/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3785 - auroc: 0.7599 - val_loss: 0.4126 - val_auroc: 0.6820\n",
      "\n",
      "Epoch 00028: val_auroc did not improve from 0.69386\n",
      "Epoch 29/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3782 - auroc: 0.7606 - val_loss: 0.4125 - val_auroc: 0.6820\n",
      "\n",
      "Epoch 00029: val_auroc did not improve from 0.69386\n",
      "Epoch 30/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3772 - auroc: 0.7635 - val_loss: 0.4123 - val_auroc: 0.6820\n",
      "\n",
      "Epoch 00030: val_auroc did not improve from 0.69386\n",
      "Epoch 31/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3782 - auroc: 0.7597 - val_loss: 0.4120 - val_auroc: 0.6816\n",
      "\n",
      "Epoch 00031: val_auroc did not improve from 0.69386\n",
      "Epoch 32/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3787 - auroc: 0.7591 - val_loss: 0.4127 - val_auroc: 0.6813\n",
      "\n",
      "Epoch 00032: val_auroc did not improve from 0.69386\n",
      "Epoch 33/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3776 - auroc: 0.7613 - val_loss: 0.4124 - val_auroc: 0.6812\n",
      "\n",
      "Epoch 00033: val_auroc did not improve from 0.69386\n",
      "Epoch 34/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3786 - auroc: 0.7592 - val_loss: 0.4125 - val_auroc: 0.6813\n",
      "\n",
      "Epoch 00034: val_auroc did not improve from 0.69386\n",
      "Epoch 35/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3777 - auroc: 0.7611 - val_loss: 0.4123 - val_auroc: 0.6812\n",
      "\n",
      "Epoch 00035: val_auroc did not improve from 0.69386\n",
      "Epoch 36/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3759 - auroc: 0.7639 - val_loss: 0.4125 - val_auroc: 0.6808\n",
      "\n",
      "Epoch 00036: val_auroc did not improve from 0.69386\n",
      "Epoch 37/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3758 - auroc: 0.7645 - val_loss: 0.4125 - val_auroc: 0.6806\n",
      "\n",
      "Epoch 00037: val_auroc did not improve from 0.69386\n",
      "Epoch 38/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3767 - auroc: 0.7630 - val_loss: 0.4123 - val_auroc: 0.6807\n",
      "\n",
      "Epoch 00038: val_auroc did not improve from 0.69386\n",
      "Epoch 39/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3766 - auroc: 0.7618 - val_loss: 0.4124 - val_auroc: 0.6804\n",
      "\n",
      "Epoch 00039: val_auroc did not improve from 0.69386\n",
      "Epoch 40/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3762 - auroc: 0.7640 - val_loss: 0.4125 - val_auroc: 0.6805\n",
      "\n",
      "Epoch 00040: val_auroc did not improve from 0.69386\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3760 - auroc: 0.7649 - val_loss: 0.4122 - val_auroc: 0.6800\n",
      "\n",
      "Epoch 00041: val_auroc did not improve from 0.69386\n",
      "Epoch 42/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3760 - auroc: 0.7656 - val_loss: 0.4123 - val_auroc: 0.6800\n",
      "\n",
      "Epoch 00042: val_auroc did not improve from 0.69386\n",
      "Epoch 43/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3757 - auroc: 0.7649 - val_loss: 0.4121 - val_auroc: 0.6800\n",
      "\n",
      "Epoch 00043: val_auroc did not improve from 0.69386\n",
      "Epoch 44/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3756 - auroc: 0.7652 - val_loss: 0.4123 - val_auroc: 0.6797\n",
      "\n",
      "Epoch 00044: val_auroc did not improve from 0.69386\n",
      "Epoch 45/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3749 - auroc: 0.7668 - val_loss: 0.4121 - val_auroc: 0.6796\n",
      "\n",
      "Epoch 00045: val_auroc did not improve from 0.69386\n",
      "Epoch 46/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3753 - auroc: 0.7661 - val_loss: 0.4121 - val_auroc: 0.6794\n",
      "\n",
      "Epoch 00046: val_auroc did not improve from 0.69386\n",
      "Epoch 47/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3751 - auroc: 0.7663 - val_loss: 0.4122 - val_auroc: 0.6794\n",
      "\n",
      "Epoch 00047: val_auroc did not improve from 0.69386\n",
      "Epoch 48/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3753 - auroc: 0.7653 - val_loss: 0.4122 - val_auroc: 0.6795\n",
      "\n",
      "Epoch 00048: val_auroc did not improve from 0.69386\n",
      "Epoch 49/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3748 - auroc: 0.7664 - val_loss: 0.4125 - val_auroc: 0.6795\n",
      "\n",
      "Epoch 00049: val_auroc did not improve from 0.69386\n",
      "Epoch 50/50\n",
      "769/769 [==============================] - 14s 18ms/step - loss: 0.3752 - auroc: 0.7647 - val_loss: 0.4124 - val_auroc: 0.6793\n",
      "\n",
      "Epoch 00050: val_auroc did not improve from 0.69386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24fb3dd5ca0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.fit(train_data,y_train_enc,\n",
    "       validation_data=(test_data,y_test_enc),\n",
    "       batch_size=128,\n",
    "       epochs=50,\n",
    "       callbacks=callbacks,\n",
    "       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cfbb47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf2caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7c301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62378c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e11f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3e1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
