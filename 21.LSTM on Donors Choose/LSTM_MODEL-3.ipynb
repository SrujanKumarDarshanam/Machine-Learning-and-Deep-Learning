{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a4142b",
   "metadata": {},
   "source": [
    "# <font color='red'> Model-3 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7fce72",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/fkQ8nGo.png'>\n",
    "ref: https://i.imgur.com/fkQ8nGo.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f94579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this model you can use the text vectorized data from model1 \n",
    "#for other than text data consider the following steps\n",
    "# you have to perform one hot encoding of categorical features. You can use onehotencoder() or countvectorizer() for the same.\n",
    "# Stack up standardised numerical features and all the one hot encoded categorical features\n",
    "#the input to conv1d layer is 3d, you can convert your 2d data to 3d using np.newaxis\n",
    "# Note - deep learning models won't work with sparse features, you have to convert them to dense features before fitting in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62ad2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense, Input , Dropout\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf286e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c22ca13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13dca5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file\n",
    "import pandas as pd\n",
    "p1 = '/content/drive/MyDrive/AAIC/Assignments/LSTM on Donors Choose/preprocessed_data_final.csv'\n",
    "p2 = \"C:/Users/darsh/Downloads/Srujan/Donars Choose Assignment/preprocessed_data_final.csv\"\n",
    "df = pd.read_csv(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751cab69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>resource_summary_contains_numerical_digits</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>essay</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_resource_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [teacher_number_of_previously_posted_projects, resource_summary_contains_numerical_digits, price, quantity, school_state, project_grade_category, clean_categories, clean_subcategories, teacher_prefix, project_is_approved, essay, project_title, project_resource_summary]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df[pd.isnull(df).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b096cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['project_is_approved'].values\n",
    "df.drop(['project_is_approved'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35975376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180e151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d94c2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>resource_summary_contains_numerical_digits</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>essay</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_resource_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92061</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>234.95</td>\n",
       "      <td>4</td>\n",
       "      <td>nc</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>music_arts</td>\n",
       "      <td>visualarts</td>\n",
       "      <td>mrs</td>\n",
       "      <td>school center wonderful community many student...</td>\n",
       "      <td>Family Time is Art Time!</td>\n",
       "      <td>My students need a heavy duty paper cutter, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83229</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>324.06</td>\n",
       "      <td>6</td>\n",
       "      <td>nc</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>math_science</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>ms</td>\n",
       "      <td>teach wonderful group sixth grade students hig...</td>\n",
       "      <td>Math Lounge Part 2</td>\n",
       "      <td>My students need a chair with pillows for thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       teacher_number_of_previously_posted_projects  \\\n",
       "92061                                             6   \n",
       "83229                                            47   \n",
       "\n",
       "       resource_summary_contains_numerical_digits   price  quantity  \\\n",
       "92061                                           0  234.95         4   \n",
       "83229                                           0  324.06         6   \n",
       "\n",
       "      school_state project_grade_category clean_categories  \\\n",
       "92061           nc             grades_3_5       music_arts   \n",
       "83229           nc             grades_6_8     math_science   \n",
       "\n",
       "      clean_subcategories teacher_prefix  \\\n",
       "92061          visualarts            mrs   \n",
       "83229         mathematics             ms   \n",
       "\n",
       "                                                   essay  \\\n",
       "92061  school center wonderful community many student...   \n",
       "83229  teach wonderful group sixth grade students hig...   \n",
       "\n",
       "                  project_title  \\\n",
       "92061  Family Time is Art Time!   \n",
       "83229        Math Lounge Part 2   \n",
       "\n",
       "                                project_resource_summary  \n",
       "92061  My students need a heavy duty paper cutter, pa...  \n",
       "83229  My students need a chair with pillows for thei...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21733862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e315a64",
   "metadata": {},
   "source": [
    "# <font color='blue'> Text vectorization </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12840291",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = ['essay','project_title','project_resource_summary',]\n",
    "X_train['total_text_input'] = X_train['essay'] + ' ' + X_train['project_title'] + ' ' + X_train['project_resource_summary']\n",
    "X_test['total_text_input'] = X_test['essay'] + ' ' + X_test['project_title'] + ' ' + X_test['project_resource_summary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84107b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 1000\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "# Tokenize our training data\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(X_train['total_text_input'])\n",
    "\n",
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Encode training data sentences into sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train['total_text_input'])\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test['total_text_input'])\n",
    "\n",
    "# Get max training sequence length\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "\n",
    "# Pad the training sequences\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "test_padded = pad_sequences(test_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0f7bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padded training shape, Test Shape: (81936, 355) (27312, 355)\n",
      "Training sequences data type: <class 'list'> <class 'list'>\n",
      "Padded Training sequences data type: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Output the results of our work\n",
    "#print(\"Word index:\\n\", word_index)\n",
    "#print(\"\\nTraining sequences:\\n\", train_sequences)\n",
    "#print(\"\\nPadded training sequences:\\n\", train_padded)\n",
    "print(\"\\nPadded training shape, Test Shape:\", train_padded.shape,test_padded.shape)\n",
    "print(\"Training sequences data type:\", type(train_sequences),type(test_sequences))\n",
    "print(\"Padded Training sequences data type:\", type(train_padded),type(test_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcade94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26fec12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:19, 20102.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "p1 = '/content/drive/MyDrive/AAIC/Assignments/LSTM on Donors Choose/glove.6B.300d.txt'\n",
    "p2 = \"C:/Users/darsh/Downloads/Srujan/Donars Choose Assignment/glove.6B.300d.txt\"\n",
    "f = open(p2,encoding=\"utf8\")\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('\\nLoaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "269e4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0edb1426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88893275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d784b1",
   "metadata": {},
   "source": [
    "# <font color='blue'> categorical and Numerical vectorization </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc5726f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this model you can use the text vectorized data from model1 \n",
    "#for other than text data consider the following steps\n",
    "# you have to perform one hot encoding of categorical features. You can use onehotencoder() or countvectorizer() for the same.\n",
    "# Stack up standardised numerical features and all the one hot encoded categorical features\n",
    "#the input to conv1d layer is 3d, you can convert your 2d data to 3d using np.newaxis\n",
    "# Note - deep learning models won't work with sparse features, you have to convert them to dense features before fitting in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6ad7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_input = ['school_state','project_grade_category','clean_categories', 'clean_subcategories','teacher_prefix',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa22b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1f88617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school_state (81936, 51) (27312, 51)\n",
      "project_grade_category (81936, 4) (27312, 4)\n",
      "clean_categories (81936, 51) (27312, 51)\n",
      "clean_subcategories (81936, 393) (27312, 393)\n",
      "teacher_prefix (81936, 5) (27312, 5)\n"
     ]
    }
   ],
   "source": [
    "categorical_data_train = dict()\n",
    "categorical_data_test = dict()\n",
    "for i in categorical_input:\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_enc = vectorizer.fit_transform(X_train[i].values)\n",
    "    test_enc = vectorizer.transform(X_test[i].values)\n",
    "    categorical_data_train[i+'_enc'] = train_enc#.todense()\n",
    "    categorical_data_test[i+'_test_enc'] = test_enc#.todense()\n",
    "    print(i,train_enc.shape,test_enc.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9e95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d41b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_input = ['teacher_number_of_previously_posted_projects',\n",
    "                  'resource_summary_contains_numerical_digits',\n",
    "                  'price','quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a5cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49c6bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler  = preprocessing.MinMaxScaler().fit(X_train[numerical_input].values)\n",
    "std_data_train = (pd.DataFrame(scaler.transform(X_train[numerical_input]),columns=numerical_input))\n",
    "std_data_test = (pd.DataFrame(scaler.transform(X_test[numerical_input]),columns=numerical_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357184b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec3be86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_than_text_data = hstack(((std_data_train),\n",
    "                               categorical_data_train['school_state_enc'],\n",
    "                               categorical_data_train['project_grade_category_enc'],\n",
    "                               categorical_data_train['clean_categories_enc'],\n",
    "                               categorical_data_train['clean_subcategories_enc'],\n",
    "                               categorical_data_train['teacher_prefix_enc'],\n",
    "                               )).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4762d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(other_than_text_data).reshape(81936,507,1)\n",
    "#other_than_text_data = other_than_text_data.reshape(81936,507,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61052168",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_than_text_data = other_than_text_data[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52d4d207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.matrix"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(other_than_text_data.reshape(81936,508,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65860d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_than_text_data_test = np.array(hstack(((std_data_test),\n",
    "                                    categorical_data_test['school_state_test_enc'],\n",
    "                                    categorical_data_test['project_grade_category_test_enc'],\n",
    "                                    categorical_data_test['clean_categories_test_enc'],\n",
    "                                    categorical_data_test['clean_subcategories_test_enc'],\n",
    "                                    categorical_data_test['teacher_prefix_test_enc'],\n",
    "                                   )).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5bda174",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_than_text_data_test = other_than_text_data_test[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb0d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09da9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D\n",
    "\n",
    "input_seq_total_text_data = Input(shape=(maxlen,),name='input_seq_total_text_data_')\n",
    "\n",
    "emb_text_data = Embedding(input_dim=vocab_size,output_dim=300, \n",
    "                          weights=[embedding_matrix], input_length=maxlen,trainable=False,\n",
    "                          name='emb_text_data')(input_seq_total_text_data)\n",
    "lstm = LSTM(units=128,activation='tanh',return_sequences=True)(emb_text_data)\n",
    "flatten_text = Flatten()(lstm)\n",
    "\n",
    "other_than_text_data_ = Input(shape=(508,1))\n",
    "\n",
    "#other_than_text_data_ = Input(shape=(508,1),name='other_than_text_data1')\n",
    "conv1 = Conv1D(filters=128,kernel_size=3,strides=1,)(other_than_text_data_)\n",
    "conv2 = Conv1D(filters=128,kernel_size=3,strides=1,)(conv1)\n",
    "flat1 = Flatten()(conv2)\n",
    "\n",
    "concat = concatenate([flatten_text,flat1])\n",
    "\n",
    "d1 = Dense(units=256,activation='relu',kernel_initializer='he_normal',\n",
    "           kernel_regularizer=l2(0.000001),name='dense_layer_1')(concat)\n",
    "drop1 = Dropout(0.5)(d1)\n",
    "\n",
    "d2 = Dense(units=256,activation='relu',kernel_initializer='he_normal',\n",
    "           kernel_regularizer=l2(0.000001),name='dense_layer_2')(drop1)\n",
    "drop2 = Dropout(0.5)(d2)\n",
    "\n",
    "bn1 = BatchNormalization()(drop2)\n",
    "\n",
    "d3 = Dense(units=256,activation='relu',kernel_initializer='he_normal',\n",
    "           kernel_regularizer=l2(0.000001),name='dense_layer_3')(bn1)\n",
    "drop3 = Dropout(0.5)(d3)\n",
    "\n",
    "d4 = Dense(units=256,activation='relu',kernel_initializer='he_normal',\n",
    "           kernel_regularizer=l2(0.000001),name='dense_layer_4')(drop3)\n",
    "drop4 = Dropout(0.5)(d4)\n",
    "\n",
    "\n",
    "\n",
    "d5 = Dense(units=256,activation='relu',kernel_initializer='he_normal',\n",
    "           kernel_regularizer=l2(0.000001),name='dense_layer_5')(drop4)\n",
    "drop5 = Dropout(0.5)(d5)\n",
    "\n",
    "\n",
    "output = Dense(units=2,activation='softmax')(drop5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e440cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b473c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = Model(inputs=[input_seq_total_text_data,other_than_text_data_],\n",
    "           outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "debb92ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_seq_total_text_data_ (Inp [(None, 355)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 508, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "emb_text_data (Embedding)       (None, 355, 300)     17031600    input_seq_total_text_data_[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 506, 128)     512         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 355, 128)     219648      emb_text_data[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 504, 128)     49280       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 45440)        0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64512)        0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 109952)       0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer_1 (Dense)           (None, 256)          28147968    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer_2 (Dense)           (None, 256)          65792       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_layer_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256)          1024        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer_3 (Dense)           (None, 256)          65792       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_layer_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer_4 (Dense)           (None, 256)          65792       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           dense_layer_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer_5 (Dense)           (None, 256)          65792       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_layer_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            514         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 45,713,714\n",
      "Trainable params: 28,681,602\n",
      "Non-trainable params: 17,032,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392e49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f662f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [test_padded,other_than_text_data_test]\n",
    "\n",
    "train_data = [train_padded,other_than_text_data]             \n",
    "\n",
    "y_train_enc =  tensorflow.keras.utils.to_categorical(y_train, 2)\n",
    "y_test_enc =  tensorflow.keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fadceaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc1(y_true, y_pred):\n",
    "    if len(np.unique(y_true[:,1])) == 1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return roc_auc_score( y_true, y_pred, average='macro', sample_weight=None).astype('double')\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    return tensorflow.numpy_function(auc1, (y_true, y_pred), tensorflow.double)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./LSTM_Model_3.h5', save_weights_only=False,save_best_only=True, \\\n",
    "                                       mode='max', monitor='val_auroc',verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auroc', patience=2,mode='max',verbose=1),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6eeaad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[auroc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7177339",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = len(y_train_enc)//128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9729f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35ca8b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "641/641 [==============================] - 54s 69ms/step - loss: 0.5118 - auroc: 0.5022 - val_loss: 0.5550 - val_auroc: 0.4308\n",
      "\n",
      "Epoch 00001: val_auroc improved from -inf to 0.43082, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 2/50\n",
      "641/641 [==============================] - 43s 67ms/step - loss: 0.4400 - auroc: 0.5046 - val_loss: 0.5034 - val_auroc: 0.5878\n",
      "\n",
      "Epoch 00002: val_auroc improved from 0.43082 to 0.58782, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 3/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.4362 - auroc: 0.5027 - val_loss: 0.4607 - val_auroc: 0.4182\n",
      "\n",
      "Epoch 00003: val_auroc did not improve from 0.58782\n",
      "Epoch 4/50\n",
      "641/641 [==============================] - 43s 67ms/step - loss: 0.4340 - auroc: 0.4999 - val_loss: 0.4464 - val_auroc: 0.4063\n",
      "\n",
      "Epoch 00004: val_auroc did not improve from 0.58782\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.4306 - auroc: 0.5147 - val_loss: 0.4420 - val_auroc: 0.5728\n",
      "\n",
      "Epoch 00005: val_auroc did not improve from 0.58782\n",
      "Epoch 6/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.4251 - auroc: 0.5709 - val_loss: 0.4403 - val_auroc: 0.5917\n",
      "\n",
      "Epoch 00006: val_auroc improved from 0.58782 to 0.59168, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 7/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.4183 - auroc: 0.6282 - val_loss: 0.4433 - val_auroc: 0.6401\n",
      "\n",
      "Epoch 00007: val_auroc improved from 0.59168 to 0.64011, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 8/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.4132 - auroc: 0.6569 - val_loss: 0.4341 - val_auroc: 0.6761\n",
      "\n",
      "Epoch 00008: val_auroc improved from 0.64011 to 0.67609, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 9/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.4075 - auroc: 0.6781 - val_loss: 0.4418 - val_auroc: 0.6946\n",
      "\n",
      "Epoch 00009: val_auroc improved from 0.67609 to 0.69463, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 10/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.3993 - auroc: 0.6966 - val_loss: 0.4381 - val_auroc: 0.7081\n",
      "\n",
      "Epoch 00010: val_auroc improved from 0.69463 to 0.70806, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 11/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.3950 - auroc: 0.7085 - val_loss: 0.4498 - val_auroc: 0.7127\n",
      "\n",
      "Epoch 00011: val_auroc improved from 0.70806 to 0.71275, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 12/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3919 - auroc: 0.7163 - val_loss: 0.4535 - val_auroc: 0.7213\n",
      "\n",
      "Epoch 00012: val_auroc improved from 0.71275 to 0.72134, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 13/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3875 - auroc: 0.7243 - val_loss: 0.4437 - val_auroc: 0.7282\n",
      "\n",
      "Epoch 00013: val_auroc improved from 0.72134 to 0.72824, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 14/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3843 - auroc: 0.7325 - val_loss: 0.4197 - val_auroc: 0.7323\n",
      "\n",
      "Epoch 00014: val_auroc improved from 0.72824 to 0.73231, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 15/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3815 - auroc: 0.7380 - val_loss: 0.4375 - val_auroc: 0.7352\n",
      "\n",
      "Epoch 00015: val_auroc improved from 0.73231 to 0.73521, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 16/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3775 - auroc: 0.7447 - val_loss: 0.4171 - val_auroc: 0.7378\n",
      "\n",
      "Epoch 00016: val_auroc improved from 0.73521 to 0.73778, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 17/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3753 - auroc: 0.7513 - val_loss: 0.4349 - val_auroc: 0.7427\n",
      "\n",
      "Epoch 00017: val_auroc improved from 0.73778 to 0.74266, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 18/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3718 - auroc: 0.7564 - val_loss: 0.4117 - val_auroc: 0.7440\n",
      "\n",
      "Epoch 00018: val_auroc improved from 0.74266 to 0.74399, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 19/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3686 - auroc: 0.7616 - val_loss: 0.4129 - val_auroc: 0.7466\n",
      "\n",
      "Epoch 00019: val_auroc improved from 0.74399 to 0.74662, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 20/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3658 - auroc: 0.7666 - val_loss: 0.4286 - val_auroc: 0.7476\n",
      "\n",
      "Epoch 00020: val_auroc improved from 0.74662 to 0.74756, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 21/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3629 - auroc: 0.7724 - val_loss: 0.4080 - val_auroc: 0.7434\n",
      "\n",
      "Epoch 00021: val_auroc did not improve from 0.74756\n",
      "Epoch 22/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3589 - auroc: 0.7773 - val_loss: 0.4190 - val_auroc: 0.7493\n",
      "\n",
      "Epoch 00022: val_auroc improved from 0.74756 to 0.74928, saving model to .\\LSTM_Model_3.h5\n",
      "Epoch 23/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3544 - auroc: 0.7843 - val_loss: 0.4033 - val_auroc: 0.7441\n",
      "\n",
      "Epoch 00023: val_auroc did not improve from 0.74928\n",
      "Epoch 24/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3512 - auroc: 0.7898 - val_loss: 0.4430 - val_auroc: 0.7459\n",
      "\n",
      "Epoch 00024: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 25/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.3407 - auroc: 0.8015 - val_loss: 0.4239 - val_auroc: 0.7467\n",
      "\n",
      "Epoch 00025: val_auroc did not improve from 0.74928\n",
      "Epoch 26/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3372 - auroc: 0.8038 - val_loss: 0.4274 - val_auroc: 0.7443\n",
      "\n",
      "Epoch 00026: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 27/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3342 - auroc: 0.8086 - val_loss: 0.4291 - val_auroc: 0.7443\n",
      "\n",
      "Epoch 00027: val_auroc did not improve from 0.74928\n",
      "Epoch 28/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3348 - auroc: 0.8081 - val_loss: 0.4284 - val_auroc: 0.7446\n",
      "\n",
      "Epoch 00028: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 29/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3333 - auroc: 0.8092 - val_loss: 0.4299 - val_auroc: 0.7446\n",
      "\n",
      "Epoch 00029: val_auroc did not improve from 0.74928\n",
      "Epoch 30/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3349 - auroc: 0.8074 - val_loss: 0.4292 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00030: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 31/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3346 - auroc: 0.8080 - val_loss: 0.4290 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00031: val_auroc did not improve from 0.74928\n",
      "Epoch 32/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3329 - auroc: 0.8097 - val_loss: 0.4288 - val_auroc: 0.7446\n",
      "\n",
      "Epoch 00032: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 33/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.3347 - auroc: 0.8074 - val_loss: 0.4291 - val_auroc: 0.7446\n",
      "\n",
      "Epoch 00033: val_auroc did not improve from 0.74928\n",
      "Epoch 34/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3337 - auroc: 0.8100 - val_loss: 0.4297 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00034: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 35/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3355 - auroc: 0.8080 - val_loss: 0.4288 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00035: val_auroc did not improve from 0.74928\n",
      "Epoch 36/50\n",
      "641/641 [==============================] - 43s 67ms/step - loss: 0.3341 - auroc: 0.8073 - val_loss: 0.4295 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00036: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641/641 [==============================] - 44s 68ms/step - loss: 0.3349 - auroc: 0.8094 - val_loss: 0.4296 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00037: val_auroc did not improve from 0.74928\n",
      "Epoch 38/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3341 - auroc: 0.8076 - val_loss: 0.4291 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00038: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "Epoch 39/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3349 - auroc: 0.8086 - val_loss: 0.4289 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00039: val_auroc did not improve from 0.74928\n",
      "Epoch 40/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3333 - auroc: 0.8119 - val_loss: 0.4291 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00040: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "Epoch 41/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3345 - auroc: 0.8102 - val_loss: 0.4288 - val_auroc: 0.7444\n",
      "\n",
      "Epoch 00041: val_auroc did not improve from 0.74928\n",
      "Epoch 42/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3342 - auroc: 0.8097 - val_loss: 0.4296 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00042: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "Epoch 43/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.3350 - auroc: 0.8081 - val_loss: 0.4298 - val_auroc: 0.7446\n",
      "\n",
      "Epoch 00043: val_auroc did not improve from 0.74928\n",
      "Epoch 44/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.3350 - auroc: 0.8082 - val_loss: 0.4289 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00044: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "Epoch 45/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3355 - auroc: 0.8080 - val_loss: 0.4291 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00045: val_auroc did not improve from 0.74928\n",
      "Epoch 46/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3337 - auroc: 0.8098 - val_loss: 0.4285 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00046: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "Epoch 47/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3357 - auroc: 0.8068 - val_loss: 0.4290 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00047: val_auroc did not improve from 0.74928\n",
      "Epoch 48/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.3340 - auroc: 0.8106 - val_loss: 0.4291 - val_auroc: 0.7445\n",
      "\n",
      "Epoch 00048: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "Epoch 49/50\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.3348 - auroc: 0.8093 - val_loss: 0.4294 - val_auroc: 0.7444\n",
      "\n",
      "Epoch 00049: val_auroc did not improve from 0.74928\n",
      "Epoch 50/50\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.3348 - auroc: 0.8088 - val_loss: 0.4288 - val_auroc: 0.7446\n",
      "\n",
      "Epoch 00050: val_auroc did not improve from 0.74928\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c6f49d340>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(train_data,y_train_enc,\n",
    "       validation_data=(test_data,y_test_enc),\n",
    "       batch_size=128,\n",
    "       epochs=50,\n",
    "       callbacks=callbacks,\n",
    "       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87c221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33cde72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f073ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dfcd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a78d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
