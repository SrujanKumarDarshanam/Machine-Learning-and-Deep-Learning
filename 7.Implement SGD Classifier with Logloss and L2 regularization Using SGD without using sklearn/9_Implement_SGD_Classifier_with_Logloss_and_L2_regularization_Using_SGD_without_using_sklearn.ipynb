{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKaywbqZP2uF"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzSwHqk0P6yV"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHGYsqx-P-b3"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JysNv4YBP3co"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxpqkPksQELd"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bKOtNgbeQA8S"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dR3UI57cQGv2",
    "outputId": "e6b04e62-7c66-41c7-cc15-d1afe6faedce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8fagnPgQKq3"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DfonAAz0QIdb"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q_NpGMmbQM2o"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSIQaRPEQObA",
    "outputId": "95aa08d7-8869-4819-cbeb-5b51b21ca148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PG0Qi1joQTId"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGs27JxzQds8"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amP50GusQenc",
    "outputId": "da45b0da-3338-4d2d-bdf8-38ed849ce30e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlbwLinNQhIN",
    "outputId": "2b53d910-5931-41cc-ef2c-69454c1335c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
      "Total training time: 0.15 seconds.\n",
      "Convergence after 14 epochs took 0.15 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=x_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2HK8UMRQjLw",
    "outputId": "c79d404d-69ce-4049-da12-792f7ee29b2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
       "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
       "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
       " (1, 15),\n",
       " array([-1.30580538]))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6L5jfzNQuzB"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98Sx_NCPQyT5"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXzhTZ1RQ119"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PVYyISs3QqET"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    b = 0\n",
    "    w = np.zeros_like(dim)\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3Z_sd_IbV7we"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMQXnHz-Q3tg",
    "outputId": "4c58947e-6ce3-47ea-8ca2-0b5f3d227d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=x_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MALEAsZ6RCRI"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0AqPEm9NQ6uf",
    "outputId": "132cfce1-9fa1-4626-cfb6-a2ba1051d27e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=x_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKs-bf2bRMA5"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T39lrkrROhJ"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nBBU457xREuH"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4wvxebBRSeD"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Mpluk4HRQZI",
    "outputId": "7883ac47-91ed-4532-f5da-9e52e1f7de2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B34WkajyRWdv"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQ-NdIykRZyb"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7OuJRgYFRUXN"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    l=0\n",
    "    #print(y_pred)\n",
    "    for i in range(len(y_true)):\n",
    "      l+= ( (y_true[i]*(math.log10(y_pred[i]))) + ((1-y_true[i])*(math.log10(1-y_pred[i]))) )\n",
    "\n",
    "    loss = (-1/len(y_true))*l\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0sGzsCsReRi"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIGYmTt6Rb33",
    "outputId": "7c72a2b9-57cf-4702-9534-d95ec67f7d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "  loss=logloss(true,pred)\n",
    "  assert(loss==0.07644900402910389)\n",
    "  return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EETpC_vjRi5f"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytjydppTRlqh"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IAOuT0nkO_3L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fbk7vG7DRgCc"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    #print(x.shape,w.shape)\n",
    "    z = np.dot(x,w) + b\n",
    "    #print(z)\n",
    "    #print(((y-sigmoid(z))),x)\n",
    "    a = ((y-sigmoid(z))*x)\n",
    "    #print(a)\n",
    "    b = ((alpha/N)*w)\n",
    "    dw = a-b\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7rpCFJhRpUB"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPJZOsL1RngR",
    "outputId": "a8768137-dfa1-419d-ca64-b62024034ade"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "  assert(np.sum(grad_dw)==2.613689585)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(x_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RhpIBdMRvh9"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3HNvcxaRyRD"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BmwciOY6RsBZ"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "     '''In this function, we will compute gradient w.r.to b '''\n",
    "     z = ( (np.dot(x,w)) + b )\n",
    "     db = (y-(sigmoid(z)))\n",
    "     return (db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8hJZYGHR3y2"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7xa4piBR1F6",
    "outputId": "886ce2ec-1446-4147-d1fc-040d9976c300"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(grad_db==-0.5)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(x_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4zAn3_WR8Az"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfQg22dZOe98",
    "outputId": "6f1952fa-fc8d-4a35-a74c-9241710532f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1978933333333333\n",
      "1.19864\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    w = list(w)\n",
    "    for i in range(N):\n",
    "        z = np.dot(X[i],w) + b\n",
    "        predict.append(sigmoid(z)) \n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,x_train))/len(x_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,x_test))/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GwbdpPv7R51B"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "def train(x_train,y_train,x_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    #implement the code as follows\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    # for every epoch\n",
    "        # for every data point(X_train,y_train)\n",
    "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
    "           #compute gradient w.r.to b (call the gradient_db() function)\n",
    "           #update w, b\n",
    "        # predict the output of x_train[for all data points in X_train] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the train loss values in a list\n",
    "        # predict the output of x_test[for all data points in X_test] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the test loss values in a list\n",
    "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
    "    w,b = initialize_weights(x_train[0])\n",
    "    N=len(x_train)\n",
    "    tr_loss,ts_loss = [],[]\n",
    "    #loss = OrderedDict()\n",
    "    initial_loss = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "      #print(epoch)\n",
    "      for i in range(x_train.shape[0]):\n",
    "        dw = gradient_dw(x_train[i],y_train[i],w,b,alpha,N)\n",
    "        db = gradient_db(x_train[i],y_train[i],w,b)\n",
    "        w += (eta0*dw)\n",
    "        b += (eta0*db)\n",
    "      y_pred_tr,y_pred_ts = pred(w,b,x_train),pred(w,b,x_test)\n",
    "      tr_loss.append(logloss(y_train,y_pred_tr))\n",
    "      ts_loss.append(logloss(y_test,y_pred_ts))\n",
    "      #loss[logloss(y_test,y_pred_ts)] = w\n",
    "      #print(y_train,y_pred_tr)\n",
    "      #print(y_test,y_pred_ts)\n",
    "      #ts_los = logloss(y_test,y_pred_ts)\n",
    "      #if abs(initial_loss - ts_los  ) <= (10**(-3)):\n",
    "      #  print('(ts_los - initial_loss):',(ts_los, initial_loss),abs(ts_los - initial_loss),'\\n')\n",
    "      #  break\n",
    "      #print('(ts_los - initial_loss):',(ts_los, initial_loss),abs(ts_los - initial_loss),'\\n')\n",
    "      #initial_loss = ts_los\n",
    "    return w,b,tr_loss,ts_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yv7INtApSH0M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YDCdlHtSL-b",
    "outputId": "6121ea30-1204-4694-a547-fb3f11b4beef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:20<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(x_train)\n",
    "epochs=14\n",
    "w,b,tr_loss,ts_loss=train(x_train,y_train,x_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxePIdSKSCeC"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVcGm_-VSFGz"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giafjJK7SAJb",
    "outputId": "8ea0c956-75ad-4aa5-8b20-f2dfa3c676ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-4.75139040e-03,  7.60245639e-03,  1.85102713e-03,\n",
       "          6.50362355e-05,  1.54498740e-03,  2.34086809e-03,\n",
       "         -9.09928936e-04,  2.16124544e-03,  5.21959720e-03,\n",
       "         -4.49834999e-03,  1.23628554e-03,  2.54417563e-03,\n",
       "          1.74962845e-03, -1.28756176e-03,  1.05365463e-03]]),\n",
       " array([0.00279952]))"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kt08Ld2MSJ2G"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "TqUJ4HI8F4aa",
    "outputId": "0c48b9d7-f682-4aae-c0cd-45e16b1f926f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Epoch number vs train , test loss')\n",
    "plt.plot(tr_loss,label='train-loss')\n",
    "plt.plot(ts_loss,label='test-loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_UznA7tlIhwR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "9_Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
